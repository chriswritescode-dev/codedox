# Database Configuration
# For local development: use localhost
# For Docker: use postgres (container name) or host.docker.internal for host DB
DB_HOST=localhost
DB_PORT=5432
DB_NAME=codedox
DB_USER=postgres
DB_PASSWORD=postgres

# Code Extraction LLM Configuration
# Enable/disable LLM extraction (when false, uses page title and context for basic extraction)
CODE_ENABLE_LLM_EXTRACTION=false
# Required only if LLM extraction is enabled: Set your LLM API key
CODE_LLM_API_KEY=your-api-key-here

# Model name - use the exact model name your LLM provider expects - this can be used with a local model I recommend 
# Examples: gpt-4o-mini, Qwen/Qwen3-Coder-30B-A3B-Instruct , Qwen/Qwen3-4B-Instruct-2507 (good opensource local model options)
CODE_LLM_EXTRACTION_MODEL=gpt-4o-mini

# Optional: Custom LLM endpoint (for local LLMs like LM STUDIO, Ollama, etc.)
# Leave commented to use OpenAI
# CODE_LLM_BASE_URL=http://localhost:8001/v1

# Number of parallel LLM requests for code description
CODE_LLM_NUM_PARALLEL=5


# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000
# CORS origins as comma-separated values
API_CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:8000 
API_MAX_REQUEST_SIZE=10485760  # 10MB

# MCP Authentication Configuration
# Enable authentication for MCP endpoints (recommended for remote deployments)
MCP_AUTH_ENABLED=false
# Authentication token for MCP access - generate with: openssl rand -hex 32
MCP_AUTH_TOKEN=your-secure-token-here
# Optional: Multiple tokens for different clients (comma-separated)
# MCP_AUTH_TOKENS=token1,token2,token3

# Crawling Configuration
CRAWL_DEFAULT_MAX_DEPTH=2
CRAWL_MAX_PAGES_PER_JOB=500
CRAWL_RESPECT_ROBOTS_TXT=true
CRAWL_MAX_CONCURRENT_PAGES=3
CRAWL_CONTENT_SIZE_LIMIT=50000
# Custom user agent for HTTP requests (defaults to Chrome browser if not set)
CRAWL_USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
CRAWL_MAX_CONCURRENT_SESSIONS=20
# Maximum concurrent crawl sessions per job (default: 5)
CRAWL_MAX_CONCURRENT_CRAWLS=5
# Timeout in seconds when cancelling crawl tasks (default: 5.0)
CRAWL_TASK_CANCELLATION_TIMEOUT=5.0
# Seconds without heartbeat before considering job stalled (default: 60)
CRAWL_HEARTBEAT_STALL_THRESHOLD=60

# Code Extraction Configuration
CODE_MAX_CODE_BLOCK_SIZE=50000
CODE_PRESERVE_CONTEXT_CHARS=500
CODE_MIN_CODE_LINES=2
CODE_EXTRACT_FUNCTIONS=true
CODE_EXTRACT_IMPORTS=true
CODE_DETECT_FRAMEWORKS=true
CODE_ENABLE_CONTEXT_EXTRACTION=true
CODE_MAX_CONTEXT_LENGTH=1000
  # Optional: set to false to disable auto code formatting

# Search Configuration
SEARCH_MAX_RESULTS=50
SEARCH_ENABLE_FUZZY_SEARCH=true
SEARCH_BOOST_RECENT_DAYS=7
SEARCH_SNIPPET_PREVIEW_LENGTH=200
SEARCH_DEFAULT_MAX_RESULTS=10
SEARCH_MIN_SCORE=0.1

# Upload Configuration
UPLOAD_MAX_FILE_SIZE=10485760  # 10MB per file
UPLOAD_MAX_TOTAL_SIZE=524288000  # 500MB total for batch uploads

# Environment Configuration
ENVIRONMENT=development
DEBUG=false
OUTPUT_SEPARATOR=----------------------------------------

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE=logs/codedox.log
LOG_MAX_SIZE=10485760  # 10MB
LOG_BACKUP_COUNT=5

# Optional: Test Environment
# TESTING=true  # Set to skip certain startup tasks during tests
# TEST_DB_HOST=localhost  # Override DB_HOST for tests
# TEST_DB_PORT=5432       # Override DB_PORT for tests
# TEST_DB_NAME=codedox_test  # Override DB_NAME for tests
# TEST_DB_USER=postgres   # Override DB_USER for tests
# TEST_DB_PASSWORD=postgres  # Override DB_PASSWORD for tests

